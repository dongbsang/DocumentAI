### êµ¬ì¡°ì„¤ê³„

[ì‚¬ìš©ì ì²´í¬ë°•ìŠ¤: "ì†ê¸€ì”¨ ì¸ì‹"] âœ… ë˜ëŠ” âŒ
              â”‚
              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚     OCR ë¶„ê¸° ì²˜ë¦¬     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚
        â–¼           â–¼
[Tesseract OCR]   [EasyOCR]
   (ë¹ ë¥´ê³         (ì†ê¸€ì”¨ë„ 
    ì •í™•í•¨)         ì¸ì‹ ê°€ëŠ¥)
        â”‚           â”‚
        â””â”€â”€â”€â”€â”€â†’ í›„ì²˜ë¦¬ ë° ê²°ê³¼ ì¶œë ¥

------------------------------------------------------------------------------------------------------------------------

### ìµœì´ˆ í•´ì•¼í•˜ëŠ” ê²ƒ
 .env.example íŒŒì¼ì„ ë³µì‚¬í•´ì„œ .env íŒŒì¼ë¡œ ë§Œë“­ë‹ˆë‹¤
  1) cp .env.example .env
  2) .env ì—ì„œ í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤
  3) ë³´ì•ˆì„ ìœ„í•´ ë¯¼ê°ì •ë³´ëŠ” .env ì—ë§Œ ì €ì¥
  4) (ì¶”í›„) OPENAI_API_KEY ì œê±° ì˜ˆì •

------------------------------------------------------------------------------------------------------------------------

## ğŸš€ ê°œë°œ í™˜ê²½(í™˜ê²½ êµ¬ì„±) ì„¤ì •
í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ë…ë¦½ëœ Python í™˜ê²½ì„ ë§Œë“¤ê³ , í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ í•œ ë²ˆì— ì„¤ì¹˜í•˜ì„¸ìš”.
### 1. ê°€ìƒí™˜ê²½ ìƒì„±í•˜ê¸°
cd backend
python -m venv .venv
### 2. ê°€ìƒí™˜ê²½ í™œì„±í™”
.\.venv\Scripts\Activate.ps1
### 3. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜í•˜ê¸°
pip install -r requirements.txt
1) flask ì‚¬ìš© ì‹œ import flask ì˜¤ë¥˜ ì—†ì´ ë™ì‘
2) openai í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ì‹œ import openai ì˜¤ë¥˜ ì—†ì´ ë™ì‘
### 4. ê°€ìƒí™˜ê²½ ë‚˜ê°€ê¸°
deactivate

------------------------------------------------------------------------------------------------------------------------

## ğŸ§  LLM ëª¨ë¸ ì„¤ì¹˜ ê°€ì´ë“œ (mistral-7b-instruct-v0.1.Q5_K_M.gguf)
ì´ í”„ë¡œì íŠ¸ëŠ” ë¡œì»¬ LLM ëª¨ë¸ì¸ Mistral 7B Instruct (.gguf) í˜•ì‹ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
ì•„ë˜ ì ˆì°¨ë¥¼ ë”°ë¼ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³ , ì‹¤í–‰ ê²½ë¡œì— ë°°ì¹˜í•´ ì£¼ì„¸ìš”.
ğŸ“ 1. ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„
mkdir -p backend/app/models
ğŸ”— 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ëª¨ë¸ íŒŒì¼ì€ HuggingFaceì—ì„œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ëª…ë ¹ì–´ ì¤‘ íƒ 1:

âœ… ë°©ë²• 1: git lfsë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
# Git LFSê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
git lfs install
git clone https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF
cp Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q5_K_M.gguf backend/app/models/
âœ… ë°©ë²• 2: ì§ì ‘ ë‹¤ìš´ë¡œë“œ (wget or ë¸Œë¼ìš°ì €)

# wget ì‚¬ìš© ì‹œ
wget -O backend/app/models/mistral-7b-instruct-v0.1.Q5_K_M.gguf \
https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_K_M.gguf
ë˜ëŠ” ë¸Œë¼ìš°ì €ì—ì„œ ì•„ë˜ ë§í¬ ì ‘ì† í›„ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ:
ğŸ‘‰ https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/tree/main

âœ… 3. ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ ë””ë ‰í† ë¦¬ í™•ì¸
ìµœì¢…ì ìœ¼ë¡œ ë‹¤ìŒ ê²½ë¡œì— ëª¨ë¸ì´ ìœ„ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:

backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ mistral-7b-instruct-v0.1.Q5_K_M.gguf
âš ï¸ ì£¼ì˜ ì‚¬í•­
í•´ë‹¹ ëª¨ë¸ì€ ì•½ 4GB ì´ìƒì´ë¯€ë¡œ ì¶©ë¶„í•œ ë””ìŠ¤í¬ ìš©ëŸ‰ì´ í•„ìš”í•©ë‹ˆë‹¤.

ìµœì´ˆ ì‹¤í–‰ ì‹œ CPU í™˜ê²½ì—ì„œëŠ” ì†ë„ê°€ ë‹¤ì†Œ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (GPU ê°€ì†ì€ ì„ íƒì ìœ¼ë¡œ êµ¬ì„± ê°€ëŠ¥)

------------------------------------------------------------------------------------------------------------------------

ğŸ§  LLM ëª¨ë¸ ë° llama-cpp ì„¤ì¹˜ ê°€ì´ë“œ
ì´ í”„ë¡œì íŠ¸ëŠ” ë¬¸ì„œ AI íŒŒì´í”„ë¼ì¸ì—ì„œ ë¡œì»¬ LLM (Mistral-7B) ëª¨ë¸ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ llama-cpp-python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì•„ë˜ ì ˆì°¨ì— ë”°ë¼ í™˜ê²½ì„ ì„¸íŒ…í•´ ì£¼ì„¸ìš”.

ğŸ“¦ 1. Python í™˜ê²½ ì„¤ì •
Python 3.10+ ì´ìƒì´ ê¶Œì¥ë©ë‹ˆë‹¤.

python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install --upgrade pip
ğŸ§± 2. llama-cpp-python ì„¤ì¹˜
llama-cpp-pythonì€ ë¡œì»¬ì—ì„œ GGUF í¬ë§· LLMì„ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê²½ëŸ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

âœ… CMake ê¸°ë°˜ ìˆ˜ë™ ì„¤ì¹˜
cd backend/llama-cpp-python

# CPU ì „ìš© ì„¤ì¹˜
pip install -r requirements.txt
pip install .

# GPU ì‚¬ìš© (CUDA)
CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install .
ğŸ’» Windows í™˜ê²½ - Visual Studio C++ ë¹Œë“œ ë„êµ¬ ì„¤ì¹˜
Windowsì—ì„œëŠ” C++ ì»´íŒŒì¼ì„ ìœ„í•´ Visual Studio Build Toolsê°€ í•„ìš”í•©ë‹ˆë‹¤.

ğŸ”§ ì„¤ì¹˜ ë°©ë²•:
ì•„ë˜ ë§í¬ì—ì„œ Visual Studio Build Tools ì„¤ì¹˜:
ğŸ‘‰ https://visualstudio.microsoft.com/visual-cpp-build-tools/

ì„¤ì¹˜ ì‹œ ë‹¤ìŒ êµ¬ì„±ìš”ì†Œë¥¼ ë°˜ë“œì‹œ ì²´í¬:
"C++ build tools"
"Windows 10 SDK" ë˜ëŠ” "Windows 11 SDK"
"CMake tools for Windows"
ì„¤ì¹˜ í›„ ì¬ë¶€íŒ… (í•„ìš” ì‹œ)

ğŸ“¥ 3. Mistral ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
í”„ë¡œì íŠ¸ëŠ” mistral-7b-instruct-v0.1.Q5_K_M.gguf ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Hugging Faceì—ì„œ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ì•„ë˜ ëª…ë ¹ì–´ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.

âœ… ìë™ ë‹¤ìš´ë¡œë“œ (wget ì‚¬ìš©)

mkdir -p backend/app/models

wget -O backend/app/models/mistral-7b-instruct-v0.1.Q5_K_M.gguf \
https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_K_M.gguf
ë˜ëŠ” ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ:
ğŸ‘‰ https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF

ğŸ§ª 4. ì‹¤í–‰ ì˜ˆì‹œ (Python)
from llama_cpp import Llama

llm = Llama(
    model_path="backend/app/models/mistral-7b-instruct-v0.1.Q5_K_M.gguf",
    n_ctx=2048,
    n_gpu_layers=0,  # CPU í™˜ê²½: 0, GPU í™˜ê²½: ì ì ˆíˆ ì¡°ì •
    verbose=True
)

response = llm("Q: Hello, who are you?\nA:", max_tokens=100)
print(response)


ğŸ“Œ ì°¸ê³ 
ëª¨ë¸ íŒŒì¼ì€ 4GB ì´ìƒì´ë¯€ë¡œ Gitì— ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
GPU ì‚¬ìš©ì„ ìœ„í•´ì„œëŠ” CUDAê°€ ì„¤ì¹˜ëœ í™˜ê²½ì´ í•„ìš”í•©ë‹ˆë‹¤.
ë¡œì»¬ LLM ì‹¤í–‰ ì‹œ ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ì´ ë†’ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (16GB+ ê¶Œì¥).

------------------------------------------------------------------------------

### ì‹¤í–‰ë°©ë²•
âœ… 3ë‹¨ê³„: ë™ì‹œ ì‹¤í–‰ (ì„ íƒì‚¬í•­)
ë‘ ê°œë¥¼ í•œ ë²ˆì— ì‹¤í–‰í•˜ê³  ì‹¶ë‹¤ë©´ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•  ìˆ˜ ìˆì–´ìš”:
-----------------------------------
ë°©ë²• A: VS Codeì—ì„œ ë‘ ê°œì˜ í„°ë¯¸ë„ë¡œ ì‹¤í–‰
í•˜ë‚˜ëŠ” backendì—ì„œ flask run

í•˜ë‚˜ëŠ” frontendì—ì„œ npm start
-----------------------------------
ë°©ë²• B: start-all.sh (bash ìŠ¤í¬ë¦½íŠ¸, WSL ë˜ëŠ” Git Bashì—ì„œë§Œ ê°€ëŠ¥)
bash

'ìƒµ'!/bin/bash
(ìµœì´ˆë§Œ) python -m venv .venv
.venv/Scripts/activate
cd backend
set FLASK_APP=app.py
set FLASK_ENV=development  // ìë™ ë¦¬ë¡œë“œ + ë””ë²„ê·¸ ëª¨ë“œ
flask run
cd ../frontend
npm start
----------------------------------


