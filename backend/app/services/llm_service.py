from langchain_ollama import OllamaLLM
from app.services.pdf_service import (
    extract_text_from_pdf,
    extract_images_from_pdf,
)
from app.services.ocr_service import extract_text_from_image
from app.services.doc_service import convert_docx_to_pdf_bytes
from app.services.prompt_service import get_prompt_template
from app.services.text_splitter_service import split_text
from app.services.vector_store_service import create_vectorstore_from_chunks
from app.services.upload_service import FileFormat


# âœ… OllamaëŠ” model_path í•„ìš” ì—†ìŒ
llm = OllamaLLM(
    model="mistral",   # ì„¤ì¹˜ëœ Ollama ëª¨ë¸ ì´ë¦„
    temperature=0.3,
    top_p=0.95
)


def analyze_document(
    file_bytes: bytes,
    file_format: str,
    category: str,
    use_handwriting: bool = False
) -> str:
    """
    ë¬¸ì„œ ë¶„ì„
    """
    try:
        text = ""

        # âœ… 1. í¬ë§· ë¶„ê¸° ì²˜ë¦¬
        if file_format == FileFormat.SEARCHABLE_PDF.value:
            text = extract_text_from_pdf(file_bytes)

        elif file_format == FileFormat.SCANNED_PDF.value:
            images = extract_images_from_pdf(file_bytes)
            text = "\n".join(extract_text_from_image(img) for img in images)
            return {"error": f"[ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹] {file_format}"}

        elif file_format == FileFormat.IMAGE.value:
            text = extract_text_from_image(file_bytes)

        elif file_format == FileFormat.WORD.value:
            print("ğŸ“„ Word ë¬¸ì„œ ê°ì§€ â†’ PDF ë³€í™˜ ì¤‘...")
            try:
                pdf_bytes = convert_docx_to_pdf_bytes(file_bytes)
                text = extract_text_from_pdf(pdf_bytes)
            except Exception as e:
                return {"error": f"Word â†’ PDF ë³€í™˜ ì‹¤íŒ¨: {str(e)}"}
        elif file_format == FileFormat.HWP.value:
            # âš ï¸ í–¥í›„ êµ¬í˜„ í•„ìš”: hwp â†’ pdf ë³€í™˜ í›„ ë‹¤ì‹œ ë¶„ì„
            text = "[í•´ë‹¹ ë¬¸ì„œ ìœ í˜•ì€ ì•„ì§ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.]"
            return {"error": text}

        else:
            return {"error": f"[ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹] {file_format}"}

        # âœ… 2. í›„ì²˜ë¦¬: deduplication
        text = deduplicate_lines(text)

        if not text.strip():
            text = "[í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.]"

        # âœ… 3. í…ìŠ¤íŠ¸ â†’ chunk â†’ vectorstore
        chunks = split_text(text)
        retriever = create_vectorstore_from_chunks(chunks).as_retriever()

        prompt = get_prompt_template(
            context=text,
            category=category,
            use_handwriting=use_handwriting
        )

        print("start---------------------------------------")
        response = llm.invoke(prompt)
        print("end---------------------------------------")

        return {
            "text": text,
            "chunks": chunks,
            "llm_output": response.strip() if isinstance(response, str) else str(response)
        }

    except Exception as e:
        return f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


def deduplicate_lines(text: str) -> str:
    """_summary_

    Args:
        text (str): _description_

    Returns:
        str: _description_
    """
    seen = set()
    result = []
    for line in text.splitlines():
        stripped = line.strip()
        if stripped and stripped not in seen:
            seen.add(stripped)
            result.append(stripped)
    return "\n".join(result)